{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MemoTag Voice-Based Cognitive Decline Detection\n",
    "\n",
    "This notebook demonstrates the analysis pipeline for detecting cognitive decline indicators from voice samples.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Load and preprocess audio data\n",
    "2. Extract audio features\n",
    "3. Transcribe speech and extract linguistic features\n",
    "4. Apply unsupervised ML for pattern detection\n",
    "5. Visualize results and generate insights\n",
    "6. Create a final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Add the parent directory to path to import from src\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Import project modules\n",
    "from src.audio_processing import AudioProcessor\n",
    "from src.text_processing import TextProcessor\n",
    "from src.model import CognitiveDeclineModel\n",
    "from src.visualization import VisualizationGenerator\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams[\"font.size\"] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Sample Data\n",
    "\n",
    "For this proof-of-concept, we'll use publicly available cognitive assessment speech samples. \n",
    "\n",
    "You can download sample data from sources like:\n",
    "- DementiaBank's Pitt Corpus (https://dementia.talkbank.org/)\n",
    "- Mozilla Common Voice dataset (with filtering)\n",
    "- Simulated recordings with cognitive speech patterns\n",
    "\n",
    "For privacy reasons, we'll use a small set of simulated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Directory with sample audio files\n",
    "data_dir = \"../data/raw\"\n",
    "\n",
    "# For this notebook, we assume files are already downloaded\n",
    "# List all audio files in the directory\n",
    "audio_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) \n",
    "               if f.endswith(('.wav', '.mp3', '.ogg', '.flac', '.m4a'))]\n",
    "\n",
    "print(f\"Found {len(audio_files)} audio files\")\n",
    "\n",
    "# Display a sample audio file if available\n",
    "if audio_files:\n",
    "    display(Audio(audio_files[0]))\n",
    "else:\n",
    "    print(\"No audio files found. Please download sample files to ../data/raw/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process Audio and Extract Features\n",
    "\n",
    "Now we'll process the audio files and extract features that may indicate cognitive decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the audio processor\n",
    "audio_processor = AudioProcessor()\n",
    "\n",
    "# Process all audio files and extract features\n",
    "all_audio_features = []\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    print(f\"Processing {os.path.basename(audio_file)}...\")\n",
    "    try:\n",
    "        # Extract all audio features\n",
    "        features = audio_processor.extract_all_features(audio_file)\n",
    "        all_audio_features.append(features)\n",
    "        print(f\"  Transcript: {features['transcript'][:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {audio_file}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "audio_df = pd.DataFrame(all_audio_features)\n",
    "audio_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract Linguistic Features from Transcripts\n",
    "\n",
    "Now we'll analyze the transcribed text to extract linguistic features that may indicate cognitive decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the text processor\n",
    "text_processor = TextProcessor()\n",
    "\n",
    "# Extract text features from transcripts\n",
    "text_features = []\n",
    "\n",
    "for index, row in audio_df.iterrows():\n",
    "    transcript = row.get('transcript', '')\n",
    "    if transcript:\n",
    "        print(f\"Analyzing transcript {index+1}...\")\n",
    "        features = text_processor.extract_all_features(transcript)\n",
    "        features['file_path'] = row['file_path']  # Add file_path for joining later\n",
    "        text_features.append(features)\n",
    "    else:\n",
    "        print(f\"No transcript available for sample {index+1}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "text_df = pd.DataFrame(text_features)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Combine Audio and Text Features\n",
    "\n",
    "Let's combine the audio and text features into a single dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Merge audio and text features on file_path\n",
    "if not text_df.empty:\n",
    "    # Merge on file_path\n",
    "    combined_df = pd.merge(audio_df, text_df, on='file_path', how='left', suffixes=('_audio', '_text'))\n",
    "else:\n",
    "    # Just use audio features if no text features available\n",
    "    combined_df = audio_df.copy()\n",
    "\n",
    "print(f\"Combined dataset shape: {combined_df.shape}\")\n",
    "\n",
    "# Display the columns\n",
    "print(\"\\nFeatures in combined dataset:\")\n",
    "for col in combined_df.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Feature Distributions\n",
    "\n",
    "Let's visualize key features to understand their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the visualization generator\n",
    "viz_dir = \"../data/visualizations\"\n",
    "if not os.path.exists(viz_dir):\n",
    "    os.makedirs(viz_dir)\n",
    "    \n",
    "viz_generator = VisualizationGenerator(output_dir=viz_dir)\n",
    "\n",
    "# Select key features for visualization\n",
    "audio_features = [\n",
    "    'pause_count', 'avg_pause_duration', 'pause_rate',\n",
    "    'pitch_mean', 'pitch_variability_coefficient',\n",
    "    'spectral_flatness_mean'\n",
    "]\n",
    "\n",
    "text_features = [\n",
    "    'hesitation_ratio', 'word_finding_difficulty_ratio',\n",
    "    'avg_sentence_length', 'type_token_ratio',\n",
    "    'syntactic_complexity'\n",
    "]\n",
    "\n",
    "# Plot audio features if available\n",
    "valid_audio_features = [f for f in audio_features if f in combined_df.columns]\n",
    "if valid_audio_features:\n",
    "    viz_generator.plot_feature_distribution(combined_df, valid_audio_features, \n",
    "                                           filename=\"audio_feature_distributions.png\")\n",
    "\n",
    "# Plot text features if available\n",
    "valid_text_features = [f for f in text_features if f in combined_df.columns]\n",
    "if valid_text_features:\n",
    "    viz_generator.plot_feature_distribution(combined_df, valid_text_features, \n",
    "                                           filename=\"text_feature_distributions.png\")\n",
    "\n",
    "# Plot correlation matrix\n",
    "viz_generator.plot_feature_correlations(combined_df, filename=\"feature_correlations.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Apply Unsupervised Learning\n",
    "\n",
    "Now we'll apply unsupervised learning techniques to identify patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the model\n",
    "model_dir = \"../models\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "model = CognitiveDeclineModel(model_dir=model_dir)\n",
    "\n",
    "# Train the model\n",
    "training_results = model.train(combined_df)\n",
    "\n",
    "print(\"Training results:\")\n",
    "for key, value in training_results.items():\n",
    "    if key == 'top_features':\n",
    "        print(\"\\nTop features:\")\n",
    "        for feature, importance in value:\n",
    "            print(f\"  - {feature}: {importance:.3f}\")\n",
    "    elif key == 'cluster_stats':\n",
    "        print(\"\\nCluster statistics:\")\n",
    "        for cluster, stats in value.items():\n",
    "            print(f\"  - {cluster}: {stats}\")\n",
    "    else:\n",
    "        print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions and Visualize Results\n",
    "\n",
    "Let's predict cognitive decline risk scores for our samples and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Make predictions on the same data\n",
    "# In a real scenario, we would use separate training and testing sets\n",
    "predictions = model.predict(combined_df)\n",
    "\n",
    "print(\"Prediction results:\")\n",
    "print(f\"Average risk score: {predictions['average_risk_score']:.2f}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "for i, pred in enumerate(predictions['predictions']):\n",
    "    print(f\"Sample {i+1}: Risk score: {pred['risk_score']:.2f}, Level: {pred['risk_level']}\")\n",
    "\n",
    "# Plot risk scores\n",
    "viz_generator.plot_risk_scores(predictions['predictions'], filename=\"risk_scores.png\")\n",
    "\n",
    "# Plot feature importance\n",
    "viz_generator.plot_top_features(model.get_feature_importance(), filename=\"feature_importance.png\")\n",
    "\n",
    "# Plot dimensionality reduction with cluster labels\n",
    "if 'cluster' in predictions['predictions'][0]:\n",
    "    cluster_labels = [p['cluster'] for p in predictions['predictions']]\n",
    "    viz_generator.plot_dimensionality_reduction(combined_df, labels=cluster_labels, \n",
    "                                               method='pca', filename=\"feature_clustering_pca.png\")\n",
    "    viz_generator.plot_dimensionality_reduction(combined_df, labels=cluster_labels, \n",
    "                                               method='tsne', filename=\"feature_clustering_tsne.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate Comprehensive Report\n",
    "\n",
    "Finally, let's generate a comprehensive report of our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate a report\n",
    "report = model.generate_report(combined_df, predictions)\n",
    "\n",
    "# Display report sections\n",
    "print(\"=== COGNITIVE DECLINE DETECTION REPORT ===\")\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\n--- Overall Statistics ---\")\n",
    "stats = report['overall_statistics']\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Key indicators\n",
    "print(\"\\n--- Key Indicators ---\")\n",
    "for indicator in report['key_indicators']:\n",
    "    direction = \"increases\" if indicator['correlation'] > 0 else \"decreases\"\n",
    "    print(f\"{indicator['feature']}: correlation {indicator['correlation']:.3f} ({direction} risk)\")\n",
    "\n",
    "# Cluster analysis\n",
    "print(\"\\n--- Cluster Analysis ---\")\n",
    "for cluster in report['cluster_analysis']:\n",
    "    print(f\"Cluster {cluster['cluster_id']}: {cluster['sample_count']} samples, \"\n",
    "          f\"avg risk {cluster['avg_risk_score']:.2f}, {cluster['high_risk_percentage']:.1f}% high risk\")\n",
    "\n",
    "# Create summary dashboard visualization\n",
    "viz_generator.create_summary_dashboard(combined_df, predictions, report, \n",
    "                                      filename=\"cognitive_decline_dashboard.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Conclusions and Future Work\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "From our analysis, we've identified several key indicators of potential cognitive decline:\n",
    "\n",
    "1. **Speech Patterns**:\n",
    "   - Increased pause frequency and duration\n",
    "   - Reduced speech rate\n",
    "   - Lower pitch variability\n",
    "\n",
    "2. **Linguistic Features**:\n",
    "   - Higher hesitation marker frequency\n",
    "   - Increased word-finding difficulties\n",
    "   - Reduced syntactic complexity\n",
    "   - Lower lexical diversity (type-token ratio)\n",
    "\n",
    "### Modeling Approach\n",
    "\n",
    "We used an unsupervised approach combining:\n",
    "- Feature extraction (audio and linguistic)\n",
    "- Dimensionality reduction (PCA)\n",
    "- Anomaly detection (Isolation Forest)\n",
    "- Clustering (K-means)\n",
    "\n",
    "This approach allows us to identify patterns without requiring labeled data, which is crucial for early-stage development.\n",
    "\n",
    "### Future Work\n",
    "\n",
    "To make this system clinically robust, several enhancements are needed:\n",
    "\n",
    "1. **Data Collection**: Gather a large dataset of both normal and cognitively impaired speech samples.\n",
    "2. **Supervised Learning**: Train supervised models once labeled data is available.\n",
    "3. **Longitudinal Analysis**: Track changes in speech patterns over time for the same individuals.\n",
    "4. **Clinical Validation**: Partner with healthcare providers to validate findings against clinical assessments.\n",
    "5. **User Interface**: Develop a user-friendly interface for healthcare providers.\n",
    "6. **Privacy Enhancements**: Implement additional privacy measures for handling sensitive health data.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This proof-of-concept demonstrates the potential of using voice analysis for cognitive decline detection. The combination of audio feature extraction and linguistic analysis provides a rich set of indicators that can be used to identify subtle changes in cognitive function, potentially enabling earlier intervention and better outcomes for patients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
